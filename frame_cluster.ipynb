{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2767a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "the file '/home/crs/dev/peroxide/data/2.mzML' could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m     oms.MzMLFile().load(mzmL_path,exp)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exp \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m exp=\u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmzmL_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/crs/dev/peroxide/data/2.mzML\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_file\u001b[39m\u001b[34m(mzmL_path)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_file\u001b[39m(mzmL_path:\u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      4\u001b[39m     exp=oms.MSExperiment()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43moms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMzMLFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmzmL_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyopenms/_pyopenms_6.pyx:9330\u001b[39m, in \u001b[36mpyopenms._pyopenms_6.MzMLFile.load\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: the file '/home/crs/dev/peroxide/data/2.mzML' could not be found"
     ]
    }
   ],
   "source": [
    "import pyopenms as oms\n",
    "\n",
    "def load_file(mzmL_path:str):\n",
    "    exp=oms.MSExperiment()\n",
    "    oms.MzMLFile().load(mzmL_path,exp)\n",
    "    return exp \n",
    "\n",
    "exp=load_file(mzmL_path=\"/home/crs/dev/peroxide/data/2.mzML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f79e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "snr_threshold = 3\n",
    "intensity_list = []\n",
    "\n",
    "for i, spec in enumerate(exp):\n",
    "    current_intensities = {}\n",
    "    if spec.getMSLevel() != 1:\n",
    "        continue\n",
    "    \n",
    "    rt = spec.getRT()\n",
    "    mzs, intensities = spec.get_peaks()\n",
    "    \n",
    "    median_intensity = np.median(intensities)\n",
    "    mad = np.median(np.abs(intensities - median_intensity))\n",
    "    noise_sigma = 1.4826 * mad\n",
    "    if noise_sigma <= 0:\n",
    "        continue\n",
    "    \n",
    "    sn = intensities / noise_sigma\n",
    "    mask = (sn >= snr_threshold)\n",
    "    for mz, inten in zip(mzs[mask], intensities[mask]):\n",
    "        current_intensities[mz] = inten\n",
    "    intensity_list.append(current_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ppm_tolerance = 10\n",
    "zero_threshold = 0.99\n",
    "\n",
    "all_mz = []\n",
    "for frame in intensity_list:\n",
    "    all_mz.extend(frame.keys())\n",
    "all_mz = np.sort(np.array(all_mz))\n",
    "    \n",
    "merged_mz = [all_mz[0]]\n",
    "current_sum = all_mz[0]\n",
    "current_count = 1\n",
    "    \n",
    "for mz in all_mz[1:]:\n",
    "    avg_mz = current_sum / current_count\n",
    "    ppm_diff = abs(mz - avg_mz) / avg_mz * 1e6\n",
    "    if ppm_diff <= ppm_tolerance:\n",
    "        current_sum += mz\n",
    "        current_count += 1\n",
    "        merged_mz[-1] = current_sum / current_count\n",
    "    else:\n",
    "        merged_mz.append(mz)\n",
    "        current_sum = mz\n",
    "        current_count = 1\n",
    "\n",
    "mz_axis = np.array(merged_mz)\n",
    "\n",
    "intensity_matrix = np.zeros((len(intensity_list), len(mz_axis)))\n",
    "\n",
    "for i, frame in enumerate(intensity_list):\n",
    "    mzs = np.array(list(frame.keys()))\n",
    "    intens = np.array(list(frame.values()))\n",
    "    idxs = np.searchsorted(mz_axis, mzs)\n",
    "    for mz, inten, idx in zip(mzs, intens, idxs):\n",
    "        for neighbor in (idx-1, idx, idx+1):\n",
    "            if 0 <= neighbor < len(mz_axis):\n",
    "                if abs(mz - mz_axis[neighbor]) / mz * 1e6 <= ppm_tolerance:\n",
    "                    intensity_matrix[i, neighbor] = inten\n",
    "                    break\n",
    "                \n",
    "zero_ratio = np.mean(intensity_matrix == 0, axis=0)\n",
    "keep_cols = zero_ratio < zero_threshold\n",
    "intensity_matrix = intensity_matrix[:, keep_cols]\n",
    "mz_axis = mz_axis[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa65d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "intensity_df = pd.DataFrame(intensity_matrix, columns=mz_axis)\n",
    "intensity_df.to_csv(\"4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b17633",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mz = 758.5685\n",
    "mz_axis = np.array(mz_axis)\n",
    "ppm_diffs = np.abs((mz_axis - target_mz) / mz_axis * 1e6)\n",
    "nearest_idx = np.argmin(ppm_diffs)\n",
    "nearest_mz = mz_axis[nearest_idx]\n",
    "mz_intensity = np.array(intensity_matrix)[:, nearest_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb605cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "umap_model = UMAP(n_neighbors=10, min_dist=0.1, n_components=2, random_state=42)\n",
    "embedding = umap_model.fit_transform(intensity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_data = StandardScaler().fit_transform(intensity_matrix)\n",
    "dbscan_model = DBSCAN(eps=2, min_samples=5)\n",
    "dbscan_model.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e238792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=mz_intensity, cmap='viridis', s=1)\n",
    "plt.title(\"UMAP Projection of MS1 Spectra\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df42287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(dbscan_model.labels_)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=dbscan_model.labels_, s=1)\n",
    "plt.title(\"UMAP Projection of MS1 Spectra\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X = intensity_df.values\n",
    "X_centered = X - X.mean(axis=0)\n",
    "pca = PCA(n_components=2)\n",
    "scores = pca.fit_transform(X_centered)\n",
    "loadings = pca.components_.T\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(scores[:, 0], scores[:, 1], label='PC1 Scores', linewidth=1)\n",
    "plt.title('PCA Scores')\n",
    "plt.legend()\n",
    "plt.savefig(\"pca_scores.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee14fc",
   "metadata": {},
   "source": [
    "## 细胞帧提取方案一\n",
    "\n",
    "使用上面整理得到的质谱数据矩阵$X\\in\\mathbb{R}^{t\\times m}$，按行中心化，即取一个平均帧$\\boldsymbol{x}_0^T=\\frac{1}{t}\\sum\\limits_{i=0}^t\\boldsymbol{x}_i^T$，给$X$的每一行$\\boldsymbol{x}_i^T$都减去这个平均帧，然后使用一个秩一矩阵逼近它，即找到向量$\\boldsymbol{a}\\in\\mathbb{R}^{t}$和向量$\\boldsymbol{b}\\in\\mathbb{R}^m$，使得\n",
    "\n",
    "$$\\min_{\\boldsymbol{a}\\geq0, \\boldsymbol{b}\\geq0}\\|X-\\boldsymbol{a}\\boldsymbol{b}^T\\|_F^2$$\n",
    "\n",
    "其中$\\boldsymbol{a}$表示数据的时序特征，序列$\\boldsymbol{a}$上的峰值表示细胞帧；$\\boldsymbol{b}$是m/z的特征，其序列上的峰值表示细胞代谢物。\n",
    "\n",
    "目标函数$$J(\\boldsymbol{a},\\boldsymbol{b})=\\|X-\\boldsymbol{a}\\boldsymbol{b}^T\\|_F^2$$的梯度\n",
    "$$\\frac{\\partial J}{\\partial\\boldsymbol{a}}=-2X\\boldsymbol{b}+2\\|\\boldsymbol{b}\\|^2\\boldsymbol{a}$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial\\boldsymbol{b}}=-2X^T\\boldsymbol{a}+2\\|\\boldsymbol{a}\\|^2\\boldsymbol{b}$$\n",
    "\n",
    "迭代优化时，固定$\\boldsymbol{a}$，更新$\\boldsymbol{b}$为目标函数取极小值且满足非负约束时对应的值，反之亦然。即：\n",
    "$$\\boldsymbol{a}^\\text{new}=\\max(0,\\frac{X\\boldsymbol{b}}{\\|\\boldsymbol{b}\\|^2})$$\n",
    "\n",
    "$$\\boldsymbol{b}^\\text{new}=\\max(0,\\frac{X^T\\boldsymbol{a}}{\\|\\boldsymbol{a}\\|^2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank1_estimation(intensities, tol:float=1e-6, max_iter = 100):\n",
    "    a, b = np.ones((intensities.shape[0], 1)), np.ones((intensities.shape[1], 1))\n",
    "    for _ in range(max_iter):\n",
    "        a_new = intensities @ b / (b.T @ b)\n",
    "        b_new = intensities.T @ a_new / (a_new.T @ a_new)\n",
    "        if np.linalg.norm(a_new - a) < tol and np.linalg.norm(b_new - b) < tol:\n",
    "            break\n",
    "        a, b = a_new, b_new\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47701668",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = rank1_estimation(intensity_df.values)\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(a, label='Frame scores', linewidth=1)\n",
    "ax[0].set_title('Frame Scores')\n",
    "ax[1].plot(intensity_df.columns, b, label='m/z loadings', linewidth=1)\n",
    "ax[1].set_title('m/z Loadings')\n",
    "plt.savefig(\"rank1_estimation.svg\")\n",
    "print(intensity_df.columns.values[np.argsort(-b.flatten())[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd910a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "n_components = 3\n",
    "\n",
    "nmf_model = NMF(n_components)\n",
    "T = nmf_model.fit_transform(intensity_df.values)\n",
    "M = nmf_model.components_\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    ax[0, i].plot(T[:, i], label=f'Component {i+1}')\n",
    "    ax[0, i].set_title(f'Frame profile {i+1}')\n",
    "    ax[0, i].set_xlabel(\"Frame index\")\n",
    "    ax[0, i].set_ylabel(\"Relative abundance\")\n",
    "    ax[0, i].legend()\n",
    "\n",
    "for i in range(3):\n",
    "    ax[1, i].plot(intensity_df.columns.values, M[i], label=f'Component {i+1}')\n",
    "    ax[1, i].set_title(f'm/z profile {i+1}')\n",
    "    ax[1, i].set_xlabel(\"m/z\")\n",
    "    ax[1, i].set_ylabel(\"Intensity\")\n",
    "    ax[1, i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities = intensity_df.values\n",
    "med_intensity = np.median(intensities, axis=0, keepdims=True)\n",
    "intensities_1 = intensities - med_intensity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "mz = 734.5929\n",
    "mz_list = intensity_df.columns.values\n",
    "nearest_idx = np.argmin(np.abs(mz_list - mz))\n",
    "nearest_mz = mz_list[nearest_idx]\n",
    "print(nearest_idx, nearest_mz, med_intensity[0][nearest_idx], np.max(intensities_1[:,nearest_idx]))\n",
    "print(intensities_1.sum())\n",
    "plt.plot(intensities_1[:,nearest_idx], linewidth = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133efd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\n",
    "    np.array([-1, 1]),  \n",
    "    #np.array([-1, 0, 1, -1]),\n",
    "    #np.array([-1, 0, 0, 1, -1])\n",
    "]\n",
    "scores = [np.convolve(intensities[:,nearest_idx], k, mode='same') for k in kernels]\n",
    "score = np.max(np.stack(scores), axis=0)\n",
    "pulse_positions = np.where(score < np.percentile(score, 5))[0]\n",
    "plt.plot(intensities[:,nearest_idx], linewidth = 1)\n",
    "plt.scatter(pulse_positions, intensities[pulse_positions, nearest_idx], color = \"r\", s = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter\n",
    "intensities = intensity_df.values\n",
    "baseline = median_filter(intensities, size = (20,1))\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(intensities[:,nearest_idx], linewidth = 1)\n",
    "ax[0].plot(baseline[:,nearest_idx], linewidth = 1, color = \"r\")\n",
    "ax[1].plot((intensities - baseline)[:,nearest_idx])\n",
    "plt.savefig(f\"baseline_reg_at_{nearest_mz}.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a650c",
   "metadata": {},
   "source": [
    "# 细胞帧提取方案二——无监督的CyESI信号重构方案\n",
    "假设CyESI的信号$s_{m,t}$可以这样进行分解：\n",
    "$$s_{m,t} = b_{m,t} + \\sigma_m\\epsilon + c_{m,t}$$\n",
    "其中$b_{m,t}$是基线信号，通过中位数滤波器获得；$\\sigma$是背景噪音的标准差，$\\epsilon\\sim\\mathcal{N}(0,1)$；$c_{m,t}$是细胞脉冲信号，优化时受恒正约束和稀疏正则（我们希望细胞信号脉冲是正相的，且只在少数时间帧出现）。那么重构信号的目标就是在保证$c_{m,t}\\geq0$的前提下最小化损失函数\n",
    "$$\\mathcal{L} = \\sum_{m,t}\\bigg(\\frac{(s_{m,t}-b_{m,t}-c_{m,t})^2}{2\\sigma_m^2}+\\log\\sigma_m+\\lambda\\frac{c_{m,t}}{\\sigma_m}\\bigg)$$\n",
    "前两项来源于$s_{m,t}$的最大似然估计，第三项是$c_{m,t}$的L1正则。将$\\sigma_m$初始化为$r_{m,t}=s_{m,t}-b_{m,t}$的标准差，$c_{m}$初始化为$\\boldsymbol{0}_t$，使用交替优化的方式迭代更新$\\sigma$和$c$，分别求$\\mathcal{L}$对$c_{m,t}$和$\\sigma_m$的偏导得\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial c_{m,t}}=-\\frac{s_{m,t}-b_{m,t}-c_{m,t}}{\\sigma_m^2}+\\frac{\\lambda}{\\sigma_m}$$\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial\\sigma_m}=\\sum_t\\bigg(-\\frac{(s_{m,t}-b_{m,t}-c_{m,t})^2}{\\sigma_m^3}-\\frac{\\lambda c_{m,t}}{\\sigma_m^2}+\\frac{1}{\\sigma_m}\\bigg)$$\n",
    "令偏导数为0，并用软阈值确保$c_{m,t}$的稀疏性，得到\n",
    "$$\\tilde{c}_{m,t}=r_{m,t}-\\lambda\\sigma_m,\\space c_{m,t}=\\max(\\tilde{c}_{m,t} - \\tau\\sigma_m,0)$$\n",
    "$$\\sigma=\\frac{\\lambda C+\\sqrt{(\\lambda C)^2+4TR}}{2T}$$\n",
    "其中$\\tau$是用户指定的用于限制$c_{m,t}$稀疏性的超参，$R=\\sum\\limits_t(s_{m,t}-b_{m,t}-c_{m,t})^2$，$C=\\sum\\limits_t c_{m,t}$，$T$是时间帧的总数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af29720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_single_channel(s, b, lam=0.5, sigma_min=1e-3, max_iter=50, tol=1e-4):\n",
    "    \n",
    "    r = s - b\n",
    "    sigma = np.maximum(np.std(r), sigma_min)\n",
    "    c = np.zeros_like(r)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        c_new = np.maximum(r - lam * sigma, 0.0)\n",
    "        residual = s - b - c_new\n",
    "        sum_c = np.sum(c_new)\n",
    "        t = len(r)\n",
    "        term = lam * sum_c\n",
    "        sigma_new = (term + np.sqrt(term ** 2 + 4 * t * np.sum(residual))) / (2 * t)\n",
    "        sigma_new = max(sigma_new, sigma_min)\n",
    "\n",
    "        diff = np.linalg.norm(c_new - c) / (np.linalg.norm(c) + 1e-12)\n",
    "        if diff < tol:\n",
    "            c = c_new\n",
    "            sigma = sigma_new\n",
    "            break\n",
    "\n",
    "        c = c_new\n",
    "        sigma = sigma_new\n",
    "\n",
    "    return c, sigma\n",
    "\n",
    "def sparse_reconstruction_parallel(S, B, lam=0.5, sigma_min=1e-3, max_iter=50, n_jobs=-1):\n",
    "    from joblib import Parallel, delayed\n",
    "    from tqdm import tqdm\n",
    "    T, M = S.shape\n",
    "    results = Parallel(n_jobs = n_jobs)(\n",
    "        delayed(optimize_single_channel)(S[:, m], B[:, m], lam, sigma_min, max_iter)\n",
    "        for m in tqdm(range(M), desc=\"Parallel reconstruction\")\n",
    "    )\n",
    "\n",
    "    C = np.column_stack([r[0] for r in results])\n",
    "    sigma = np.array([r[1] for r in results])\n",
    "    return C, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "gs = gridspec.GridSpec(2, 2, width_ratios=[2, 1], height_ratios=[1, 1])\n",
    "ax_large = fig.add_subplot(gs[:, 0])\n",
    "ax_top = fig.add_subplot(gs[0, 1])\n",
    "ax_bottom = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "mz = 734.5929\n",
    "mz_list = intensity_df.columns.values\n",
    "nearest_idx = np.argmin(np.abs(mz_list - mz))\n",
    "nearest_mz = mz_list[nearest_idx]\n",
    "C, sigma = sparse_reconstruction_parallel(intensities, baseline, lam = 5)\n",
    "c_df = pd.DataFrame(C, columns=mz_axis)\n",
    "c_df.to_csv(\"c.csv\", index=False)\n",
    "ax_large.plot(intensities[:,nearest_idx])\n",
    "ax_large.plot(baseline[:,nearest_idx], color = \"r\")\n",
    "ax_large.plot(C[:,nearest_idx], color=\"yellow\")\n",
    "ax_top.plot(mz_axis, np.sum(C, axis = 0))\n",
    "ax_bottom.plot(np.sum(np.nan_to_num(C, nan = 0), axis = 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf49fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = rank1_estimation(np.nan_to_num(C, nan = 0.0))\n",
    "med_a = np.median(a)\n",
    "snr = 40\n",
    "idx = np.where(a - med_a > snr * med_a)[0]\n",
    "denoised = pd.DataFrame(np.concatenate([idx.reshape(len(idx), 1), intensities[idx, :]], axis = 1), \n",
    "                        columns = np.concatenate([[0], mz_axis]))\n",
    "denoised.to_csv(\"denoised.csv\", index = False)\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(a, label='Frame scores', linewidth=1)\n",
    "ax[0].set_title('Frame Scores')\n",
    "ax[1].plot(mz_axis, b, label='m/z loadings', linewidth=1)\n",
    "ax[1].set_title('m/z Loadings')\n",
    "plt.savefig(\"rank1_estimation_c.svg\")\n",
    "print(intensity_df.columns.values[np.argsort(-b.flatten())[:10]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scMM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
